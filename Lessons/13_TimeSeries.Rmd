
---
title: "13: Time Series Analysis"
author: "Environmental Data Analytics | Kateri Salk"
date: "Spring 2019"
output: pdf_document
geometry: margin=2.54cm
editor_options: 
  chunk_output_type: console
---

## LESSON OBJECTIVES
1. Describe the aspects of hierarchical models, fixed effects, and random effects
2. Choose and justify appropriate statistical models when time is an explanatory variable
3. Apply repeated measures ANOVA to datasets with temporal components

## SET UP YOUR DATA ANALYSIS SESSION

```{r, message = FALSE, warning = FALSE}
getwd()
library(tidyverse)
#install.packages("lubridate")
library(lubridate)
#install.packages("nlme")
library(nlme)
#install.packages("lsmeans")
library(lsmeans)
#install.packages("multcompView")
library(multcompView)

PeterPaul.chem <- read.csv("./Data/Processed/NTL-LTER_Lake_ChemistryPhysics_PeterPaul_Processed.csv")

# Set date to date format
PeterPaul.chem$sampledate <- as.Date(PeterPaul.chem$sampledate, 
                                               format = "%m/%d/%y")

mytheme <- theme_classic(base_size = 14) +
  theme(axis.text = element_text(color = "black"), 
        legend.position = "top")
theme_set(mytheme)

```

## HIERARCHICAL MODELS

**Hierarchical models,** or **mixed-effects models,** are a type of linear model in which explanatory variables are given a model whose parameters are also estimated by the data. The coefficients associated with explanatory variables thus may not be a single value but instead be sampled from a distribution, called the hyper-distribution, which is defined by the modeler. The advantage of the hierarchical model is that it builds capacity to describe multiple layers of stochasticity, which enables accounting of all aspects of uncertainty in a system. Specifically, we can separately model the process of interest and the sampling process. 

The coefficients of a hierarchical model are divided into two categories: **fixed effects** and **random effects.** A **fixed effect** is a factor whose levels are experimentally determined or whose interest lies in the effects of each level (e.g., covariates, treatments, interactions). A **random effect** is a factor whose levels are sampled from a larger population, or whose interest lies in the variation among them rather than the specific effect of each level. In choosing whether you are dealing with a fixed or a random effect, consider the following questions: 

  + Do you have a particular interest in the studied factor level?

  + Have you included all possible levels in the study?
  
  + Do you have interest in the variance among levels?
  
  + Do you have interest in generalizing to factor levels that you did not study?
  
One common variable in hierarchical models is **time.** Time can be a complicated explanatory variable, as it can act as either a fixed or a random effect depending on the study design and research question. Due to **temporal autocorrelation,** conditions measured at a single site will be highly influenced by the conditions preceding the sampling date. Therefore, two samples taken in relatively close temporal proximity may not necessarily be independent of one another. Treating time as a random effect will account for temporal trends in observations (e.g., diel or seasonal patterns) that may not be of interest for your study.

Another common variable in hierarchical models is **space.** In many situations, we may want to infer conditions beyond the sites that we have sampled. By treating space as a random variable, we may be able to extrapolate conditions of the response variable across a spatial gradient.

## REPEATED MEASUREMENTS AND AUTOCORRELATION

In many situations where monitoring is conducted, samples taken repeatedly at a given site may not be considered truly independent. The conditions present on a given day may be dependent on conditions present earlier in time. This is clearly an issue for the way we might traditionally think of experimental design and statistical independence, but this type of study design is often of interest in the field of environmental science. We can set up models to consider autocorrelation of time within a given place. One example of this type of model is a **repeated measures ANOVA**.

Let's think about the situation of temperature monitoring in the NTL-LTER lake sites, Peter and Paul Lakes. We might be interested to know whether surface temperatures in the summer have increased over time in response to climate change. However, we know that (a) temperature conditions on a given date are dependent on conditions earlier in the season, and (b) there is considerable variability across the summer season within a year (i.e., cooler temperatures occurring in June vs. August). We can set up a hierarchical model to deal with the autocorrelation by date as well as the variability associated with seasonality.

Let's wrangle our data and visualize a preliminary relationship between our variables of interest.
```{r}
PeterPaul.summertemp <- 
  PeterPaul.chem %>%
  select(lakename:temperature_C) %>%
  #filter for Julian days in June-August and surface measurements
  filter(daynum > 151 & daynum < 243 & depth == 0 ) %>%
  #add a "week" column to represent seasonality
  mutate(Week = week(sampledate)) %>%
  #code won't work if there are NAs
  na.exclude()

ggplot(PeterPaul.summertemp, aes(x = sampledate, y = temperature_C, color = lakename)) +
  geom_point() +
  scale_color_manual(values = c("#7fcdbb", "#253494"))
```

Next, we will determine the degree of temporal autocorrelation in our dataset. We will use the package `nlme` for our analyses. Another good package for running hierarchical, or mixed-effects, models is `lme4`. For the basic types of hierarchical models, these packages have about the same functionality.

```{r}
# Determine autocorrelation in residuals
TempTest.auto <- lme(data = PeterPaul.summertemp,
                     temperature_C ~ sampledate * lakename, 
                     random = ~1|Week)
TempTest.auto

ACF(TempTest.auto)

```
This model structure should look familiar, with a typical linear model structure and dataframe defined. The addition here is that we have defined Week as a random variable. Essentially, we are interested not in the specific effects of each week but in the variability among weeks, so we have defined it as a random effect (essentially coming from a larger distribution of seasonal variability). The ~1 statement indicates that each week has its own intercept in the model. From here, we want to take the first order correlation to specify our autocorrelation structure. From the ACF output, we take the 2nd value (the innermost group level) to define the degree of autocorrelation. This number will always fall between 0 and 1. Notice that there is a fairly large degree of autocorrelation in our variables.

We will now create a repeated measures ANOVA model now that we have defined our autocorrelation structure. The way we have set up this model, we are considering temporal autocorrelation within the levels of Week, and we have retained Week as a random effect. 

The correlation statement in the model is defined as follows: `correlation = structure(form = ~ time | subjvar)`, where structure is the autocorrelative structure (options in `?corClasses`), time is the temporal variable, and subjvar is the variable for experimental units.

```{r, warning = FALSE}
TempTest.mixed <- lme(data = PeterPaul.summertemp,
                     temperature_C ~ sampledate * lakename, 
                     random = ~1|Week,
                     #specify autocorrelation structure of order 1
                     #sampledate is duplicated in some cases, so need to split up by lake
                     correlation = corAR1(form = ~ sampledate/lakename|Week, value = 0.423),
                     #define method as restricted maximum likelihood
                     method = "REML")
summary(TempTest.mixed)

# Compare the random effects model with the fixed effects model
TempTest.fixed <- gls(data = PeterPaul.summertemp,
                      temperature_C ~ sampledate * lakename, 
                      method = "REML")
summary(TempTest.fixed)

anova(TempTest.mixed, TempTest.fixed)
# The lower the AIC, the better.
# The p-value tells us whether those models have a significantly different fit

# Post-hoc test
# This will yield groupings of temperature by lake for the average date value
TempTest.posthoc = lsmeans(TempTest.mixed, ~ sampledate * lakename)
cld(TempTest.posthoc, alpha = 0.05, Letters = letters, adjust = "tukey")

# display our final relationship
ggplot(PeterPaul.summertemp, aes(x = sampledate, y = temperature_C, color = lakename)) +
  geom_point() +
  scale_color_manual(values = c("#7fcdbb", "#253494")) +
  geom_abline(intercept = 20.47, slope = 0.0001)
```

Question: How would you interpret the collective results of your mixed effects model in the context of the study question?

> ANSWER: 
